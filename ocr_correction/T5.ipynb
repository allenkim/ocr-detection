{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "established-atlas",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, load_metric, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from ast import literal_eval\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from transformers import set_seed, DataCollatorForSeq2Seq\n",
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "from transformers.utils import check_min_version\n",
    "\n",
    "\n",
    "# Will error if the minimal version of Transformers is not installed. Remove at your own risks.\n",
    "check_min_version(\"4.6.0.dev0\")\n",
    "\n",
    "def generate_examples(row):\n",
    "    hid1, hid2 = row['hid1'], row['hid2']\n",
    "    loss1, loss2 = row['loss1'], row['loss2']\n",
    "    diff1, diff2 = row['diff1'], row['diff2']\n",
    "    ctx1, ctx2 = row['ctx1'], row['ctx2']\n",
    "    ocr1, ocr2 = ctx1[diff1[0]:diff1[1]], ctx2[diff2[0]:diff2[1]]\n",
    "    ex1 = ' '.join(ctx1[:diff1[0]]) + ' <ocr> ' + ' '.join(ocr1) + ' </ocr> ' + ' '.join(ctx1[diff1[1]:])\n",
    "    ex2 = ' '.join(ctx2[:diff2[0]]) + ' <ocr> ' + ' '.join(ocr2) + ' </ocr> ' + ' '.join(ctx2[diff2[1]:])\n",
    "    correct = \"<blank>\"\n",
    "    if loss1 < loss2:\n",
    "        if ocr1:\n",
    "            correct = ' '.join(ocr1)\n",
    "        return hid2, ex2, correct\n",
    "    else:\n",
    "        if ocr2:\n",
    "            correct = ' '.join(ocr2)\n",
    "        return hid1, ex1, correct\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = examples['orig']\n",
    "    targets = examples['corrected']\n",
    "    inputs = [inp for inp in inputs]\n",
    "    model_inputs = tokenizer(inputs, padding=True, truncation=True)\n",
    "\n",
    "    # Setup the tokenizer for targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(targets, padding=True, truncation=True)\n",
    "\n",
    "    # If we are padding here, replace all tokenizer.pad_token_id in the labels by -100 when we want to ignore\n",
    "    # padding in the loss.\n",
    "    labels[\"input_ids\"] = [\n",
    "        [(l if l != tokenizer.pad_token_id else -100) for l in label] for label in labels[\"input_ids\"]\n",
    "    ]\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "existing-nancy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 1729\n",
    "set_seed(seed)\n",
    "model_name = \"ocr_correction_model\"\n",
    "\n",
    "print(\"Loading tokenizer\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "tokenizer.add_tokens([\"<ocr>\", \"</ocr>\", \"<blank>\"], special_tokens=True)        \n",
    "tokenizer.add_special_tokens({\"additional_special_tokens\": [\"<ocr>\", \"</ocr>\", \"<blank>\"]})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5ac4c1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "953163137ae64473843312a7cf5334e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading test\")\n",
    "num_samples = 2000\n",
    "testp = Path('/home/allekim/ocr-detection/ocr_data/test.csv')\n",
    "df = pd.read_csv(testp, converters={'ctx1': eval, 'ctx2': eval, 'diff1': eval, 'diff2': eval}, nrows=num_samples)\n",
    "df[['hid', 'orig','corrected']] = df.apply(generate_examples, axis=1, result_type=\"expand\")\n",
    "test_dataset = Dataset.from_pandas(df[['hid', 'orig', 'corrected']])\n",
    "\n",
    "test_dataset = test_dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    num_proc=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "latest-motorcycle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32103, 768)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32103, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32103, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=32103, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Loading model\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained('ocr_correction_model')\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6c50a547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['attention_mask', 'corrected', 'hid', 'input_ids', 'labels', 'orig']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a3461e56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['attention_mask', 'corrected', 'hid', 'input_ids', 'labels', 'orig'],\n",
       "    num_rows: 200\n",
       "})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "543bc3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_result(example):\n",
    "#     input_ids = torch.tensor(example['input_ids'])\n",
    "#     attention_mask = torch.tensor(example['attention_mask'])\n",
    "#     print(input_ids)\n",
    "#     result = model.generate(input_ids=input_ids, attention_mask=attention_mask, output_scores=True, return_dict_in_generate=True)\n",
    "#     return {'sequences': result.sequences, 'scores': result.scores}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0c805f35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# encoded_dataset = test_dataset.map(generate_result, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30213a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset[:10]['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21d1699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = torch.tensor(test_dataset[0:32]['input_ids'])\n",
    "# y = torch.tensor(test_dataset[0:32]['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04360447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = model.generate(input_ids=x, attention_mask=y, output_scores=True, return_dict_in_generate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0720e63b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['attention_mask', 'corrected', 'hid', 'input_ids', 'labels', 'orig'],\n",
       "    num_rows: 200\n",
       "})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5c727f4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{260, 448}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([len(y) for y in test_dataset['input_ids']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5c70887e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['uc1.$b753568',\n",
       " 'uc1.b3370386',\n",
       " 'uc1.b3370386',\n",
       " 'uc1.b3370386',\n",
       " 'uc1.$b753568',\n",
       " 'uc1.b3370386',\n",
       " 'uc1.b3370386',\n",
       " 'uc1.b3370386',\n",
       " 'uc1.$b753568',\n",
       " 'uc1.$b753568',\n",
       " 'uc1.$b753568',\n",
       " 'uc1.b3370386',\n",
       " 'uc1.$b753568',\n",
       " 'uc1.b3370386',\n",
       " 'uc1.$b753568',\n",
       " 'uc1.b3370386',\n",
       " 'uc1.b3370386',\n",
       " 'uc1.b3370386',\n",
       " 'uc1.b3370386',\n",
       " 'uc1.$b753568',\n",
       " 'uc1.$b753568',\n",
       " 'uc1.$b753568',\n",
       " 'uc1.b3370386',\n",
       " 'uc1.$b753568',\n",
       " 'uc1.b3370386',\n",
       " 'uc1.$b753568',\n",
       " 'uc1.$b753568',\n",
       " 'uc1.$b753568',\n",
       " 'uc1.b3370386',\n",
       " 'uc1.b3370386',\n",
       " 'uc1.$b753568',\n",
       " 'uc1.b3370386',\n",
       " 'uc1.b3370386',\n",
       " 'uc1.b3370386',\n",
       " 'uc1.$b753568',\n",
       " 'uc1.b3370386',\n",
       " 'uc1.b3370386',\n",
       " 'uc1.b3370386',\n",
       " 'uc1.b3370386',\n",
       " 'uc1.$b753568',\n",
       " 'uc1.$b753568',\n",
       " 'uc1.b3370386',\n",
       " 'uc1.b3370386',\n",
       " 'uc1.b3370386',\n",
       " 'uc1.$b753568',\n",
       " 'uc1.b3370386',\n",
       " 'uc1.b3370386',\n",
       " 'uc1.b3370386',\n",
       " 'uc1.b3370386',\n",
       " 'uc1.$b753568',\n",
       " 'uc1.b3370386',\n",
       " 'uc1.b3370386',\n",
       " 'uc1.b3370386',\n",
       " 'uc1.b3370386',\n",
       " 'uc1.$b753568',\n",
       " 'uc1.b3370386',\n",
       " 'uc1.b3370386',\n",
       " 'uc1.$b753568',\n",
       " 'uc1.b3370386',\n",
       " 'uc1.$b753568',\n",
       " 'uc1.$b753568',\n",
       " 'uc1.b3370386',\n",
       " 'uc1.$b753568',\n",
       " 'uc1.$b753568']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['hid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4caa2390",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generated' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-125bc5e15cd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'generated' is not defined"
     ]
    }
   ],
   "source": [
    "generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "078790d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['attention_mask', 'corrected', 'hid', 'input_ids', 'labels', 'orig'],\n",
       "    num_rows: 2000\n",
       "})"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "98b8dfb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.where(generated==2)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1c0f56a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GreedySearchEncoderDecoderOutput(sequences=tensor([[    0, 32102,     1,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [    0,  2147,    18, 19161,  1765,   260,  6577,     1,     0,     0],\n",
       "        [    0,     3,    15,     7,  1169,    60,     1,     0,     0,     0],\n",
       "        [    0,    27,     1,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [    0,   326,     1,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [    0,  5376,    77,     1,     0,     0,     0,     0,     0,     0],\n",
       "        [    0,     3,  1489,    89,     3,    55,     1,     0,     0,     0],\n",
       "        [    0,     3,   184,     3,  8270,     3,   117,     1,     0,     0],\n",
       "        [    0,  3963,     1,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [    0, 14246,     1,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [    0,  1551,     1,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [    0, 32102,     1,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [    0,   207,     1,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [    0,   141,     1,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [    0,  2734,   107,   655,     1,     0,     0,     0,     0,     0],\n",
       "        [    0,  3671,     1,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [    0,    27,     1,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [    0,    27,     1,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [    0,   237,     1,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [    0,   227,     1,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [    0,     3,  2092,     1,     0,     0,     0,     0,     0,     0],\n",
       "        [    0,     3, 12105,    18,  9136,     1,     0,     0,     0,     0],\n",
       "        [    0,    13,     1,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [    0,   419, 12634,  3820,     1,     0,     0,     0,     0,     0],\n",
       "        [    0,    13,     1,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [    0,   910,   536,     1,     0,     0,     0,     0,     0,     0],\n",
       "        [    0,  1347,     1,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [    0,  5695,  1841,     1,     0,     0,     0,     0,     0,     0],\n",
       "        [    0, 32102,     1,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [    0,     3,    31,    31,     1,     0,     0,     0,     0,     0],\n",
       "        [    0,   103,     3,    55,     1,     0,     0,     0,     0,     0],\n",
       "        [    0,    27,     1,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [    0,   113,     1,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [    0,   118,     1,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [    0,     3,    58,     1,     0,     0,     0,     0,     0,     0],\n",
       "        [    0, 32102,     1,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [    0,  3655,    40,     1,     0,     0,     0,     0,     0,     0],\n",
       "        [    0,    70,     1,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [    0,    62,     1,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [    0,   293,     1,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [    0,  8627,     1,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [    0,   454, 16479,   567,     1,     0,     0,     0,     0,     0],\n",
       "        [    0,   272, 19356, 16560,   134,     1,     0,     0,     0,     0],\n",
       "        [    0,  7780,     1,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [    0,  8627,     1,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [    0,   454, 16479,   567,     1,     0,     0,     0,     0,     0],\n",
       "        [    0,   272, 19356, 16560,   134,     1,     0,     0,     0,     0],\n",
       "        [    0,  1363,     5,     1,     0,     0,     0,     0,     0,     0],\n",
       "        [    0, 12412,    17,     1,     0,     0,     0,     0,     0,     0],\n",
       "        [    0,  8627,     1,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [    0,   549,  4090,  5946,  4800, 13738,  3162,     1,     0,     0],\n",
       "        [    0,   454, 16479,   567,     1,     0,     0,     0,     0,     0],\n",
       "        [    0,   272, 19356, 16560,   134,     1,     0,     0,     0,     0],\n",
       "        [    0,    39,     1,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [    0,     3,    58,     1,     0,     0,     0,     0,     0,     0],\n",
       "        [    0,   301,     5,     1,     0,     0,     0,     0,     0,     0],\n",
       "        [    0,   301, 24796,  4170,     1,     0,     0,     0,     0,     0],\n",
       "        [    0, 19451,  1363,     5, 27815,     1,     0,     0,     0,     0],\n",
       "        [    0,  1003,  4118,     1,     0,     0,     0,     0,     0,     0],\n",
       "        [    0,   499, 12537,  1363,     5,  5653,  9434,    15,     1,     0],\n",
       "        [    0, 32102,     1,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [    0,   272,   924,    53,     1,     0,     0,     0,     0,     0],\n",
       "        [    0,  1363,     5, 12102,    17,  1306,  5653,   157,  1306,     1],\n",
       "        [    0,   116,     1,     0,     0,     0,     0,     0,     0,     0]]), scores=(tensor([[ 20.6155,  21.5038,  19.0294,  ...,  26.9691,  26.8616,  32.3435],\n",
       "        [  6.1707,   9.7899,   7.2466,  ...,   2.2172,   2.1412,   4.3128],\n",
       "        [ 15.6919,  17.8958,  15.5849,  ...,  11.4945,  11.4312,  14.7949],\n",
       "        ...,\n",
       "        [ -0.7153,   8.2232,   3.6850,  ...,  -5.2189,  -5.2262,  -3.3498],\n",
       "        [ 10.3808,  14.0079,  10.9128,  ...,   5.8616,   5.8583,   8.6737],\n",
       "        [  2.4903,   7.3805,   5.4069,  ..., -11.5810, -11.6371,  -9.5868]]), tensor([[-70.1198,  -3.9169, -26.9126,  ..., -74.2454, -74.2769, -75.6133],\n",
       "        [-26.7169,  -5.2784,  -5.0924,  ..., -35.7148, -35.7759, -35.9626],\n",
       "        [-27.0440,  -9.7690,  -0.4758,  ..., -38.4468, -38.6057, -39.2411],\n",
       "        ...,\n",
       "        [-28.3031,  -9.7541,  -6.5564,  ..., -39.4941, -39.4595, -40.2134],\n",
       "        [-25.0823,  -3.3831,  -7.2034,  ..., -40.9953, -41.0298, -41.1204],\n",
       "        [-46.0967,  -2.3149, -15.1731,  ..., -52.9664, -53.0983, -53.2800]]), tensor([[-61.0941,   2.2834, -19.8354,  ..., -59.5363, -59.4319, -59.6343],\n",
       "        [-29.1129,  -8.4492,  -8.6405,  ..., -37.6217, -37.6539, -38.0825],\n",
       "        [-33.7075,  -8.8542,  -8.2880,  ..., -46.0200, -46.0767, -46.5386],\n",
       "        ...,\n",
       "        [-33.0287,  -9.8080, -12.7953,  ..., -43.8687, -43.8701, -44.7479],\n",
       "        [-19.0617,  -1.5823,  -6.7593,  ..., -29.9150, -30.0781, -29.7191],\n",
       "        [-15.2749,   7.9833,   1.5081,  ..., -20.2594, -20.3019, -19.7555]]), tensor([[  8.1210,  17.4456,  10.0004,  ...,  15.1673,  15.3871,  18.5865],\n",
       "        [-40.9489, -11.9349, -14.1919,  ..., -48.0251, -48.1040, -48.6102],\n",
       "        [-33.0666, -11.4812, -12.4242,  ..., -49.1222, -49.3050, -49.9841],\n",
       "        ...,\n",
       "        [-27.2170,   1.1879,  -6.9342,  ..., -39.3518, -39.4037, -39.6687],\n",
       "        [-27.4174,  -8.1501,  -9.4983,  ..., -35.9810, -35.9352, -36.2858],\n",
       "        [  4.9316,  14.8460,   8.7305,  ...,  -0.5607,  -0.5172,   1.5471]]), tensor([[ 17.3831,  21.4334,  17.1527,  ...,  25.4394,  25.4853,  29.7878],\n",
       "        [-21.8705,  -1.9946,  -6.2349,  ..., -33.0849, -33.1689, -33.2483],\n",
       "        [-41.4237, -17.0896, -13.0101,  ..., -53.6268, -53.5470, -54.5950],\n",
       "        ...,\n",
       "        [-17.8831,   3.1813,  -2.9942,  ..., -29.6315, -29.6743, -29.7388],\n",
       "        [-36.2187, -10.3044, -10.1896,  ..., -42.2145, -42.0916, -42.7927],\n",
       "        [  6.2725,  14.6084,   9.5997,  ...,   0.8729,   0.8956,   3.1913]]), tensor([[ 24.0549,  25.1063,  21.3555,  ...,  31.3179,  31.2704,  36.3950],\n",
       "        [-39.8254, -15.0556, -13.4025,  ..., -52.6267, -52.8841, -54.1185],\n",
       "        [-24.0300,   3.6855,  -1.6039,  ..., -37.3176, -37.3409, -37.1202],\n",
       "        ...,\n",
       "        [ -6.5424,   6.0184,  -0.8591,  ..., -20.0659, -20.0882, -19.4092],\n",
       "        [-24.2793,  -1.0651,  -5.6113,  ..., -32.7989, -32.8703, -32.4787],\n",
       "        [  5.8018,  12.7712,   8.8370,  ...,  -2.1133,  -2.1266,   0.0695]]), tensor([[ 2.4462e+01,  2.4882e+01,  2.1338e+01,  ...,  3.1223e+01,\n",
       "          3.1141e+01,  3.6483e+01],\n",
       "        [-4.1188e+01, -1.8780e+00, -1.3535e+01,  ..., -5.2543e+01,\n",
       "         -5.2555e+01, -5.2836e+01],\n",
       "        [-2.4370e+01,  4.2971e+00, -3.2883e+00,  ..., -3.8055e+01,\n",
       "         -3.8064e+01, -3.8007e+01],\n",
       "        ...,\n",
       "        [-3.4484e+00,  7.6659e+00,  2.6400e-02,  ..., -1.4306e+01,\n",
       "         -1.4354e+01, -1.3377e+01],\n",
       "        [-3.5865e+01, -1.2751e+01, -1.0397e+01,  ..., -4.2230e+01,\n",
       "         -4.2186e+01, -4.2772e+01],\n",
       "        [ 4.6274e+00,  1.1011e+01,  7.6768e+00,  ..., -4.8754e+00,\n",
       "         -4.8974e+00, -2.8043e+00]]), tensor([[ 23.2820,  24.0957,  20.7077,  ...,  30.0548,  29.9520,  35.3450],\n",
       "        [-20.8841,   3.4526,  -3.9517,  ..., -33.5812, -33.6024, -33.5955],\n",
       "        [  7.7754,  16.1229,  10.4444,  ...,  -1.6832,  -1.6429,   0.6221],\n",
       "        ...,\n",
       "        [ -2.8132,   7.7832,   0.3963,  ..., -12.4969, -12.5567, -11.3661],\n",
       "        [-36.5380, -14.2081, -12.8873,  ..., -45.6185, -45.5137, -46.3999],\n",
       "        [  3.8711,   9.8387,   6.9303,  ...,  -6.6905,  -6.7188,  -4.6803]]), tensor([[ 22.2989,  23.3737,  20.1826,  ...,  29.0472,  28.9357,  34.3389],\n",
       "        [ -2.9256,   9.3099,   2.0670,  ..., -11.9098, -11.9195, -10.6441],\n",
       "        [  9.4836,  14.8710,  10.0469,  ...,   0.4169,   0.4558,   2.8228],\n",
       "        ...,\n",
       "        [ -2.3304,   7.9451,   0.9824,  ..., -11.0784, -11.1371,  -9.7942],\n",
       "        [-37.2658,  -0.1363, -11.4117,  ..., -48.5121, -48.5692, -48.7284],\n",
       "        [  3.4382,   9.1227,   6.5001,  ...,  -7.7729,  -7.8069,  -5.7857]])), encoder_attentions=None, encoder_hidden_states=None, decoder_attentions=None, cross_attentions=None, decoder_hidden_states=None)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0abdd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reflected-relief",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/32 [00:45<23:19, 45.16s/it]"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "i = 0\n",
    "batch_size = 64\n",
    "for i in tqdm(range(0,len(test_dataset), batch_size)):\n",
    "    x = test_dataset[i:i+batch_size]\n",
    "    input_ids = torch.tensor(x['input_ids'])\n",
    "    attention_mask = torch.tensor(x['attention_mask'])\n",
    "    result = model.generate(input_ids=input_ids, attention_mask=attention_mask, output_scores=True, return_dict_in_generate=True)\n",
    "    for j in range(len(x)):\n",
    "        scores = np.array([y[j].numpy() for y in result.scores])\n",
    "        generated = result.sequences[j].numpy()\n",
    "        end_idx = np.where(generated==1)[0]\n",
    "        if len(end_idx) > 0:\n",
    "            outtoks = tokenizer.convert_ids_to_tokens(generated)\n",
    "            final_string = tokenizer.convert_tokens_to_string(outtoks[1:end_idx[0]])\n",
    "            results.append((x['hid'][j], x['orig'][j], x['corrected'][j], final_string, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7571ed8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5cf126",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831ebfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pregnant-scanner",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results, columns=['sent', 'truth', 'gen', 'scores'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gothic-middle",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "delayed-jones",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.to_csv('new_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handled-parent",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bd7cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = df[['sent', 'truth', 'gen']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f456eac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b316f435",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['match'] = results.apply(lambda row: row['truth'] == row['gen'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cc01c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717853b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cd45cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f82499",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[(-results['match']) & (results['truth']!='<blank>') & results['gen'].apply(lambda x: '<unk>' in x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49b5a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[(results['truth']!='<blank>')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351cd020",
   "metadata": {},
   "outputs": [],
   "source": [
    "7975 / 14414"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e377ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
